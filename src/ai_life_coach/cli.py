import os
import sys
import json
from openai import OpenAI
from .prompts.tool_manager import ToolManager
from .prompts.prompt_main import prompt_main

client = OpenAI(
    api_key=os.getenv("AI_LIFE_COACH_KEY", ""), base_url="https://api.siliconflow.cn/v1"
)

model_Qwen3_30B_A3B = "Qwen/Qwen3-30B-A3B"


# Global tool manager
tool_manager = ToolManager()


# åˆå§‹åŒ–åŸºç¡€å·¥å…·é›†
def init_tools():
    """åˆå§‹åŒ–AIç”Ÿæ´»å¯¼å¸ˆçš„åŸºç¡€å·¥å…·é›†"""

    # æ¨¡æ‹Ÿå·¥å…·1ï¼šä¿å­˜ç”¨æˆ·ä¿¡æ¯
    tool_manager.add_tool(
        name="save_user_info",
        description="ä¿å­˜ç”¨æˆ·ä¸ªäººä¿¡æ¯",
        when_to_use="ç”¨æˆ·é¦–æ¬¡æä¾›ä¸ªäººä¿¡æ¯æˆ–æ›´æ–°ä¿¡æ¯æ—¶",
        parameters={
            "info_type": "ä¿¡æ¯ç±»å‹(profile/goal/problem/preference)",
            "content": "å…·ä½“ä¿¡æ¯å†…å®¹",
        },
        output="ä¿å­˜æˆåŠŸç¡®è®¤å’Œä¿¡æ¯ID",
        example="save_user_info('goal', 'æˆ‘æƒ³åœ¨6ä¸ªæœˆå†…å­¦ä¼šPythonç¼–ç¨‹')",
    )

    # æ¨¡æ‹Ÿå·¥å…·2ï¼šè·å–ç”¨æˆ·å†å²
    tool_manager.add_tool(
        name="get_user_history",
        description="è·å–ç”¨æˆ·çš„å†å²å’¨è¯¢è®°å½•",
        when_to_use="éœ€è¦äº†è§£ç”¨æˆ·è¿‡å¾€é—®é¢˜å’Œå»ºè®®å†å²æ—¶",
        parameters={
            "query_type": "æŸ¥è¯¢ç±»å‹(recent/all/by_topic)",
            "limit": "è¿”å›è®°å½•æ•°é‡(é»˜è®¤5)",
        },
        output="æŒ‰æ—¶é—´æ’åºçš„å†å²è®°å½•åˆ—è¡¨",
        example="get_user_history('recent', 3)",
    )

    # æ¨¡æ‹Ÿå·¥å…·3ï¼šæœç´¢å»ºè®®
    tool_manager.add_tool(
        name="search_advice",
        description="ä»çŸ¥è¯†åº“æœç´¢ç›¸å…³å»ºè®®",
        when_to_use="éœ€è¦ä¸ºç‰¹å®šé—®é¢˜æŸ¥æ‰¾ä¸“ä¸šå»ºè®®æ—¶",
        parameters={"topic": "æœç´¢ä¸»é¢˜å…³é”®è¯", "user_context": "ç”¨æˆ·å…·ä½“æƒ…å†µæè¿°"},
        output="ç›¸å…³å»ºè®®åˆ—è¡¨å’Œå®ç”¨æ€§è¯„åˆ†",
        example="search_advice('æ—¶é—´ç®¡ç†', 'ä¸Šç­æ—æƒ³æé«˜å·¥ä½œæ•ˆç‡')",
    )


# æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œå‡½æ•°
def execute_tool(tool_name, **kwargs):
    """æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ"""
    if tool_name == "save_user_info":
        info_type = kwargs.get("info_type", "")
        content = kwargs.get("content", "")
        return f"âœ… å·²ä¿å­˜{info_type}ä¿¡æ¯: {content[:50]}... (ID: user_info_001)"

    elif tool_name == "get_user_history":
        query_type = kwargs.get("query_type", "recent")
        limit = kwargs.get("limit", 3)
        return f"ğŸ“‹ æ‰¾åˆ°{limit}æ¡{query_type}è®°å½•:\n1. ä¸Šæ¬¡å’¨è¯¢èŒä¸šè§„åˆ’é—®é¢˜\n2. è®¨è®ºå­¦ä¹ æ–¹æ³•\n3. æ—¶é—´ç®¡ç†å»ºè®®"

    elif tool_name == "search_advice":
        topic = kwargs.get("topic", "")
        context = kwargs.get("user_context", "")
        return f"ğŸ’¡ å…³äº'{topic}'çš„å»ºè®®:\n1. åˆ¶å®šæ˜ç¡®çš„å­¦ä¹ è®¡åˆ’\n2. é‡‡ç”¨ç•ªèŒ„å·¥ä½œæ³•\n3. å®šæœŸå¤ä¹ å’Œåæ€\n(åŸºäº: {context})"

    else:
        return f"âš ï¸ æœªçŸ¥å·¥å…·: {tool_name}"


# MsgStructure: maintain memory and steps as placeholders, always fill prompt_main
def build_system_prompt(memory, steps):
    """Build the system prompt with memory and steps placeholders."""
    tools_section = "\n".join(tool_manager.tools)
    return prompt_main.format(
        memory_placeholder=memory or "(empty)",
        steps_placeholder=steps or "(empty)",
        tools_placeholder=tools_section,
    )


def chat(user_input, memory, steps, model=model_Qwen3_30B_A3B):
    """Chat with the AI model using MsgStructure."""
    system_prompt = build_system_prompt(memory, steps)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input},
    ]
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=2048,
        temperature=0.7,
    )
    return response.choices[0].message.content


def parse_tool_calls(response_text):
    """è§£æAIå›å¤ä¸­çš„å·¥å…·è°ƒç”¨ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
    tool_calls = []

    # ç®€å•çš„å·¥å…·è°ƒç”¨æ£€æµ‹ï¼ˆä½ å¯ä»¥æ ¹æ®éœ€è¦æ”¹è¿›è¿™ä¸ªè§£æé€»è¾‘ï¼‰
    import re

    # æ£€æµ‹ç±»ä¼¼ save_user_info('goal', 'æˆ‘æƒ³å­¦Python') çš„è°ƒç”¨
    patterns = [
        r"save_user_info\(['\"]([^'\"]+)['\"],\s*['\"]([^'\"]+)['\"]\)",
        r"get_user_history\(['\"]([^'\"]+)['\"],?\s*(\d+)?\)",
        r"search_advice\(['\"]([^'\"]+)['\"],\s*['\"]([^'\"]+)['\"]\)",
    ]

    for pattern in patterns:
        matches = re.findall(pattern, response_text)
        for match in matches:
            if "save_user_info" in pattern:
                tool_calls.append(
                    ("save_user_info", {"info_type": match[0], "content": match[1]})
                )
            elif "get_user_history" in pattern:
                limit = int(match[1]) if match[1] else 3
                tool_calls.append(
                    ("get_user_history", {"query_type": match[0], "limit": limit})
                )
            elif "search_advice" in pattern:
                tool_calls.append(
                    ("search_advice", {"topic": match[0], "user_context": match[1]})
                )

    return tool_calls


# MsgStructure: memory/steps are strings, not message lists
def process_with_tools(user_input, memory, steps):
    """Process user input, update memory and steps as MsgStructure placeholders."""
    # 1st round: send user_input, get AI response
    ai_response = chat(user_input, memory, steps)
    print(f"ğŸ¤– AIå¯¼å¸ˆ: {ai_response}")

    # Update steps with this round
    steps = (steps or "") + f"\n[User]: {user_input}\n[AI]: {ai_response}\n"

    # Check for tool calls
    tool_calls = parse_tool_calls(ai_response)
    if tool_calls:
        print("\nğŸ”§ æ‰§è¡Œå·¥å…·...")
        tool_results = []
        for tool_name, kwargs in tool_calls:
            print(f"   è°ƒç”¨ {tool_name}...")
            result = execute_tool(tool_name, **kwargs)
            tool_results.append(f"å·¥å…· {tool_name} ç»“æœ: {result}")
            print(f"   âœ… {result}")
        # Feedback tool results to AI
        tool_feedback = "\n".join(tool_results)
        tool_feedback_input = (
            f"å·¥å…·æ‰§è¡Œç»“æœ:\n{tool_feedback}\n\nè¯·åŸºäºè¿™äº›ç»“æœç»™å‡ºæœ€ç»ˆå»ºè®®ã€‚"
        )
        final_response = chat(tool_feedback_input, memory, steps)
        print(f"\nğŸ¯ æœ€ç»ˆå»ºè®®: {final_response}")
        steps += f"[Tool]: {tool_feedback}\n[AI]: {final_response}\n"
        return memory, steps
    return memory, steps


def main():
    """Main function, handles CLI input and MsgStructure memory/steps."""
    init_tools()
    print("ğŸŒŸ AIäººç”Ÿå¯¼å¸ˆå·²å¯åŠ¨ï¼")
    print("ğŸ’¡ æç¤ºï¼šä½ å¯ä»¥è¯¢é—®å…³äºèŒä¸šè§„åˆ’ã€å­¦ä¹ æ–¹æ³•ã€æ—¶é—´ç®¡ç†ç­‰é—®é¢˜")
    print("ğŸ”§ æˆ‘ä¼šæ ¹æ®éœ€è¦ä½¿ç”¨å·¥å…·æ¥æ›´å¥½åœ°å¸®åŠ©ä½ ")
    print("ğŸ‘‹ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")

    memory = ""  # Temporary memory placeholder
    steps = ""  # History steps placeholder

    while True:
        try:
            user_input = input("ğŸ‘¤ ä½ : ").strip()
            if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
                print("ğŸ‘‹ å†è§ï¼ç¥ä½ ç”Ÿæ´»æ„‰å¿«ï¼")
                break
            if not user_input:
                continue
            print()
            memory, steps = process_with_tools(user_input, memory, steps)
            print("\n" + "=" * 50 + "\n")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
            print("è¯·é‡è¯•...\n")


if __name__ == "__main__":
    main()
